#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Warp Proto Extractor - ä¸€é”®ä» Warp äºŒè¿›åˆ¶æå– Proto å®šä¹‰

ç”¨æ³•:
    python3 extract_warp_protos.py                    # ä½¿ç”¨é»˜è®¤è·¯å¾„
    python3 extract_warp_protos.py /path/to/binary   # æŒ‡å®šäºŒè¿›åˆ¶è·¯å¾„
    python3 extract_warp_protos.py --output ./protos # æŒ‡å®šè¾“å‡ºç›®å½•

åŠŸèƒ½:
    1. ä» Warp äºŒè¿›åˆ¶ä¸­æå–åµŒå…¥çš„ FileDescriptorProto
    2. è§£ç å¹¶ç”Ÿæˆå¯ç¼–è¯‘çš„ .proto æ–‡ä»¶
    3. ç”Ÿæˆæ¶ˆæ¯ç±»å‹æ±‡æ€»æŠ¥å‘Š
    4. ä¸é¡¹ç›®ç°æœ‰ proto è¿›è¡Œå¯¹æ¯”
"""
import argparse
import os
import re
import sys
import json
from datetime import datetime
from pathlib import Path


# ============================================================================
# Protobuf Wire Format è§£æå™¨
# ============================================================================

def read_varint(data: bytes, pos: int) -> tuple:
    """è¯»å– varint ç¼–ç çš„æ•´æ•°"""
    result = 0
    shift = 0
    while True:
        if pos >= len(data):
            raise ValueError("Incomplete varint")
        b = data[pos]
        result |= (b & 0x7f) << shift
        pos += 1
        if not (b & 0x80):
            break
        shift += 7
    return result, pos


def read_length_delimited(data: bytes, pos: int) -> tuple:
    """è¯»å–é•¿åº¦åˆ†éš”å­—æ®µ"""
    length, pos = read_varint(data, pos)
    return data[pos:pos + length], pos + length


def parse_field(data: bytes, pos: int) -> tuple:
    """è§£æå•ä¸ª protobuf å­—æ®µï¼Œè¿”å› (field_num, wire_type, value, new_pos)"""
    if pos >= len(data):
        return None, None, None, pos
    
    tag, new_pos = read_varint(data, pos)
    field_num = tag >> 3
    wire_type = tag & 0x7
    
    if wire_type == 0:  # Varint
        value, new_pos = read_varint(data, new_pos)
    elif wire_type == 1:  # 64-bit
        value = int.from_bytes(data[new_pos:new_pos + 8], 'little')
        new_pos += 8
    elif wire_type == 2:  # Length-delimited
        value, new_pos = read_length_delimited(data, new_pos)
    elif wire_type == 5:  # 32-bit
        value = int.from_bytes(data[new_pos:new_pos + 4], 'little')
        new_pos += 4
    else:
        raise ValueError(f"Unknown wire type {wire_type}")
    
    return field_num, wire_type, value, new_pos


def parse_message(data: bytes) -> dict:
    """å°† protobuf æ¶ˆæ¯è§£æä¸ºå­—æ®µå­—å…¸"""
    result = {}
    pos = 0
    while pos < len(data):
        try:
            fn, wt, val, pos = parse_field(data, pos)
            if fn is None:
                break
            if fn not in result:
                result[fn] = []
            result[fn].append((wt, val))
        except:
            break
    return result


# ============================================================================
# FileDescriptorProto è§£ç å™¨
# ============================================================================

def decode_field_descriptor(data: bytes) -> dict:
    """è§£ç  FieldDescriptorProto"""
    fields = parse_message(data)
    result = {}
    
    if 1 in fields: result['name'] = fields[1][0][1].decode('utf-8', errors='replace')
    if 3 in fields: result['number'] = fields[3][0][1]
    if 4 in fields: result['label'] = fields[4][0][1]
    if 5 in fields: result['type'] = fields[5][0][1]
    if 6 in fields: result['type_name'] = fields[6][0][1].decode('utf-8', errors='replace')
    if 9 in fields: result['oneof_index'] = fields[9][0][1]
    
    return result


def decode_message_descriptor(data: bytes) -> dict:
    """è§£ç  DescriptorProto (æ¶ˆæ¯å®šä¹‰)"""
    fields = parse_message(data)
    result = {'name': '', 'fields': [], 'nested': [], 'enums': [], 'oneofs': []}
    
    if 1 in fields:
        result['name'] = fields[1][0][1].decode('utf-8', errors='replace')
    
    if 2 in fields:
        for _, fdata in fields[2]:
            result['fields'].append(decode_field_descriptor(fdata))
    
    if 3 in fields:
        for _, ndata in fields[3]:
            result['nested'].append(decode_message_descriptor(ndata))
    
    if 4 in fields:
        for _, edata in fields[4]:
            result['enums'].append(decode_enum_descriptor(edata))
    
    if 8 in fields:
        for _, odata in fields[8]:
            oneof_fields = parse_message(odata)
            if 1 in oneof_fields:
                result['oneofs'].append(oneof_fields[1][0][1].decode('utf-8', errors='replace'))
    
    return result


def decode_enum_descriptor(data: bytes) -> dict:
    """è§£ç  EnumDescriptorProto"""
    fields = parse_message(data)
    result = {'name': '', 'values': []}
    
    if 1 in fields:
        result['name'] = fields[1][0][1].decode('utf-8', errors='replace')
    
    if 2 in fields:
        for _, vdata in fields[2]:
            vfields = parse_message(vdata)
            value = {'name': '', 'number': 0}
            if 1 in vfields: value['name'] = vfields[1][0][1].decode('utf-8', errors='replace')
            if 2 in vfields: value['number'] = vfields[2][0][1]
            result['values'].append(value)
    
    return result


def decode_file_descriptor(data: bytes) -> dict:
    """è§£ç  FileDescriptorProto"""
    fields = parse_message(data)
    result = {
        'name': '',
        'package': '',
        'dependencies': [],
        'messages': [],
        'enums': [],
        'options': {}
    }
    
    if 1 in fields: result['name'] = fields[1][0][1].decode('utf-8', errors='replace')
    if 2 in fields: result['package'] = fields[2][0][1].decode('utf-8', errors='replace')
    
    if 3 in fields:
        for _, dep in fields[3]:
            result['dependencies'].append(dep.decode('utf-8', errors='replace'))
    
    if 4 in fields:
        for _, mdata in fields[4]:
            result['messages'].append(decode_message_descriptor(mdata))
    
    if 5 in fields:
        for _, edata in fields[5]:
            result['enums'].append(decode_enum_descriptor(edata))
    
    if 8 in fields:
        opt_fields = parse_message(fields[8][0][1])
        if 11 in opt_fields:
            result['options']['go_package'] = opt_fields[11][0][1].decode('utf-8', errors='replace')
    
    return result


# ============================================================================
# Proto æ–‡ä»¶ç”Ÿæˆå™¨
# ============================================================================

TYPE_NAMES = {
    1: 'double', 2: 'float', 3: 'int64', 4: 'uint64', 5: 'int32',
    6: 'fixed64', 7: 'fixed32', 8: 'bool', 9: 'string', 10: 'group',
    11: 'message', 12: 'bytes', 13: 'uint32', 14: 'enum', 
    15: 'sfixed32', 16: 'sfixed64', 17: 'sint32', 18: 'sint64'
}


def format_field(field: dict, in_oneof: bool = False) -> str:
    """æ ¼å¼åŒ–å­—æ®µå®šä¹‰"""
    ftype = field.get('type', 0)
    
    if ftype in (11, 14):  # message or enum
        type_name = field.get('type_name', 'unknown').lstrip('.')
    else:
        type_name = TYPE_NAMES.get(ftype, f'unknown_{ftype}')
    
    label = field.get('label', 1)
    repeated = 'repeated ' if label == 3 and not in_oneof else ''
    
    return f'{repeated}{type_name} {field.get("name", "unknown")} = {field.get("number", 0)};'


def generate_enum(enum: dict, indent: int) -> list:
    """ç”Ÿæˆæšä¸¾å®šä¹‰"""
    prefix = '    ' * indent
    lines = [f'{prefix}enum {enum["name"]} {{']
    for v in enum['values']:
        lines.append(f'{prefix}    {v["name"]} = {v["number"]};')
    lines.append(f'{prefix}}}')
    return lines


def generate_message(msg: dict, indent: int) -> list:
    """é€’å½’ç”Ÿæˆæ¶ˆæ¯å®šä¹‰"""
    prefix = '    ' * indent
    lines = [f'{prefix}message {msg["name"]} {{']
    
    for enum in msg['enums']:
        lines.extend(generate_enum(enum, indent + 1))
        lines.append('')
    
    for nested in msg['nested']:
        lines.extend(generate_message(nested, indent + 1))
        lines.append('')
    
    # æŒ‰ oneof åˆ†ç»„å­—æ®µ
    oneof_fields = {i: [] for i in range(len(msg['oneofs']))}
    regular_fields = []
    
    for field in msg['fields']:
        if 'oneof_index' in field:
            idx = field['oneof_index']
            if idx in oneof_fields:
                oneof_fields[idx].append(field)
            else:
                regular_fields.append(field)
        else:
            regular_fields.append(field)
    
    for field in regular_fields:
        lines.append(f'{prefix}    {format_field(field)}')
    
    for i, oneof_name in enumerate(msg['oneofs']):
        if oneof_fields.get(i):
            lines.append(f'{prefix}    oneof {oneof_name} {{')
            for field in oneof_fields[i]:
                lines.append(f'{prefix}        {format_field(field, in_oneof=True)}')
            lines.append(f'{prefix}    }}')
    
    lines.append(f'{prefix}}}')
    return lines


def generate_proto(fd: dict) -> str:
    """ä»è§£ç çš„ FileDescriptor ç”Ÿæˆ .proto æ–‡ä»¶å†…å®¹"""
    lines = []
    lines.append(f'// ä» Warp äºŒè¿›åˆ¶è‡ªåŠ¨æå–')
    lines.append(f'// åŸå§‹æ–‡ä»¶: {fd["name"]}')
    lines.append(f'// æå–æ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}')
    lines.append('')
    lines.append('syntax = "proto3";')
    lines.append('')
    lines.append(f'package {fd["package"]};')
    lines.append('')
    
    for dep in fd['dependencies']:
        lines.append(f'import "{dep}";')
    if fd['dependencies']:
        lines.append('')
    
    if fd['options'].get('go_package'):
        lines.append(f'option go_package = "{fd["options"]["go_package"]}";')
        lines.append('')
    
    for enum in fd['enums']:
        lines.extend(generate_enum(enum, 0))
        lines.append('')
    
    for msg in fd['messages']:
        lines.extend(generate_message(msg, 0))
        lines.append('')
    
    return '\n'.join(lines)


# ============================================================================
# ä¸»æå–é€»è¾‘
# ============================================================================

def find_proto_blocks(data: bytes) -> list:
    """åœ¨äºŒè¿›åˆ¶ä¸­æŸ¥æ‰¾ proto å®šä¹‰å—"""
    # æŸ¥æ‰¾ FileDescriptorProto æ¨¡å¼: 0x0a + length + name.proto + 0x12 + length + package
    pattern = rb'\x0a([\x08-\x40])([a-z_]+\.proto)\x12([\x10-\x30])(warp\.[a-z_]+\.v\d+)'
    
    # é¦–å…ˆæ‰¾åˆ°æ‰€æœ‰ proto æ–‡ä»¶çš„èµ·å§‹ä½ç½®
    all_matches = list(re.finditer(pattern, data))
    
    results = []
    for i, match in enumerate(all_matches):
        start = match.start()
        proto_name = match.group(2).decode()
        package = match.group(4).decode()
        
        # ç¡®å®šå—çš„ç»“æŸä½ç½®ï¼šä¸‹ä¸€ä¸ª proto æ–‡ä»¶çš„å¼€å§‹æˆ–åˆç†çš„æœ€å¤§å€¼
        if i + 1 < len(all_matches):
            # ä¸‹ä¸€ä¸ª proto æ–‡ä»¶çš„å¼€å§‹ä½ç½®
            next_start = all_matches[i + 1].start()
            block_end = next_start
        else:
            # æœ€åä¸€ä¸ªæ–‡ä»¶ï¼Œä½¿ç”¨å›ºå®šå¤§å°
            block_end = start + 50000
        
        # é™åˆ¶æœ€å¤§å—å¤§å°ä¸º 200KB
        block_end = min(block_end, start + 200000)
        
        block = data[start:block_end]
        results.append({
            'offset': start,
            'proto_name': proto_name,
            'package': package,
            'data': block,
            'size': len(block)
        })
    
    return results



def find_message_types(data: bytes) -> set:
    """æŸ¥æ‰¾æ‰€æœ‰æ¶ˆæ¯ç±»å‹åç§°"""
    msg_pattern = rb'warp\.multi_agent\.v1\.([A-Z][a-zA-Z0-9]+)'
    messages = set()
    
    for match in re.finditer(msg_pattern, data):
        msg_name = match.group(1).decode()
        # è¿‡æ»¤æ‰åç¼€ R, H, B (proto ç¼–ç æ ‡è®°)
        if len(msg_name) > 1 and not msg_name.endswith(('R', 'H', 'B')):
            messages.add(msg_name)
        elif len(msg_name) > 2:
            base = msg_name[:-1]
            if base and base[0].isupper():
                messages.add(base)
    
    return messages


def extract_protos(binary_path: str, output_dir: str) -> dict:
    """ä»äºŒè¿›åˆ¶æå–æ‰€æœ‰ proto å®šä¹‰"""
    print(f"\n{'='*60}")
    print(f"Warp Proto Extractor")
    print(f"{'='*60}")
    print(f"äºŒè¿›åˆ¶: {binary_path}")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")
    
    # è¯»å–äºŒè¿›åˆ¶
    print(f"\n[1/4] è¯»å–äºŒè¿›åˆ¶æ–‡ä»¶...")
    with open(binary_path, 'rb') as f:
        data = f.read()
    print(f"      å¤§å°: {len(data) / 1024 / 1024:.2f} MB")
    
    os.makedirs(output_dir, exist_ok=True)
    
    # æŸ¥æ‰¾ proto å—
    print(f"\n[2/4] æœç´¢ Proto å®šä¹‰å—...")
    blocks = find_proto_blocks(data)
    print(f"      æ‰¾åˆ° {len(blocks)} ä¸ª proto æ–‡ä»¶")
    
    # è§£ç å¹¶ç”Ÿæˆ proto æ–‡ä»¶
    print(f"\n[3/4] è§£ç å¹¶ç”Ÿæˆ .proto æ–‡ä»¶...")
    extracted = []
    failed = []
    
    for block in blocks:
        proto_name = block['proto_name']
        try:
            fd = decode_file_descriptor(block['data'])
            proto_content = generate_proto(fd)
            
            output_path = os.path.join(output_dir, proto_name)
            with open(output_path, 'w') as f:
                f.write(proto_content)
            
            extracted.append({
                'name': proto_name,
                'package': fd['package'],
                'messages': len(fd['messages']),
                'enums': len(fd['enums']),
                'dependencies': fd['dependencies']
            })
            print(f"      âœ… {proto_name}: {len(fd['messages'])} messages, {len(fd['enums'])} enums")
            
        except Exception as e:
            failed.append({'name': proto_name, 'error': str(e)})
            print(f"      âŒ {proto_name}: {e}")
    
    # ç”Ÿæˆæ¶ˆæ¯ç±»å‹æ±‡æ€»
    print(f"\n[4/4] ç”Ÿæˆæ¶ˆæ¯ç±»å‹æ±‡æ€»...")
    message_types = find_message_types(data)
    
    # ä¿å­˜æ±‡æ€»æŠ¥å‘Š
    report = {
        'extracted_at': datetime.now().isoformat(),
        'binary_path': binary_path,
        'binary_size_mb': len(data) / 1024 / 1024,
        'proto_files': extracted,
        'failed_files': failed,
        'message_types': sorted(list(message_types)),
        'total_message_types': len(message_types)
    }
    
    report_path = os.path.join(output_dir, 'extraction_report.json')
    with open(report_path, 'w') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    # ç”Ÿæˆ README
    readme_content = generate_readme(report)
    readme_path = os.path.join(output_dir, 'README.md')
    with open(readme_path, 'w') as f:
        f.write(readme_content)
    
    print(f"\n{'='*60}")
    print(f"æå–å®Œæˆ!")
    print(f"{'='*60}")
    print(f"  æˆåŠŸ: {len(extracted)} ä¸ª proto æ–‡ä»¶")
    print(f"  å¤±è´¥: {len(failed)} ä¸ª")
    print(f"  æ¶ˆæ¯ç±»å‹: {len(message_types)} ä¸ª")
    print(f"  æŠ¥å‘Š: {report_path}")
    print(f"  README: {readme_path}")
    
    return report


def generate_readme(report: dict) -> str:
    """ç”Ÿæˆ README.md"""
    lines = [
        "# Warp Proto å®šä¹‰ (è‡ªåŠ¨æå–)",
        "",
        f"æå–æ—¶é—´: {report['extracted_at']}",
        f"äºŒè¿›åˆ¶è·¯å¾„: `{report['binary_path']}`",
        f"äºŒè¿›åˆ¶å¤§å°: {report['binary_size_mb']:.2f} MB",
        "",
        "## æå–çš„ Proto æ–‡ä»¶",
        "",
        "| æ–‡ä»¶ | æ¶ˆæ¯æ•° | æšä¸¾æ•° | ä¾èµ– |",
        "|------|--------|--------|------|"
    ]
    
    for pf in report['proto_files']:
        deps = ', '.join(pf['dependencies'][:3])
        if len(pf['dependencies']) > 3:
            deps += '...'
        lines.append(f"| `{pf['name']}` | {pf['messages']} | {pf['enums']} | {deps} |")
    
    if report['failed_files']:
        lines.extend([
            "",
            "## æå–å¤±è´¥",
            ""
        ])
        for ff in report['failed_files']:
            lines.append(f"- `{ff['name']}`: {ff['error']}")
    
    lines.extend([
        "",
        "## å‘ç°çš„æ¶ˆæ¯ç±»å‹",
        "",
        f"å…±å‘ç° {report['total_message_types']} ä¸ªæ¶ˆæ¯ç±»å‹:",
        "",
        "```"
    ])
    
    # åˆ†åˆ—æ˜¾ç¤º
    types = report['message_types']
    cols = 3
    for i in range(0, len(types), cols):
        row = types[i:i+cols]
        lines.append('  '.join(f'{t:<35}' for t in row))
    
    lines.extend([
        "```",
        "",
        "## ä½¿ç”¨æ–¹æ³•",
        "",
        "```bash",
        "# é‡æ–°æå–æœ€æ–°å®šä¹‰",
        "python3 extract_warp_protos.py",
        "",
        "# æŒ‡å®šè¾“å‡ºç›®å½•",
        "python3 extract_warp_protos.py --output ./new_protos",
        "",
        "# æŒ‡å®šäºŒè¿›åˆ¶è·¯å¾„",
        "python3 extract_warp_protos.py /path/to/warp/binary",
        "```"
    ])
    
    return '\n'.join(lines)


def compare_with_existing(output_dir: str, existing_dir: str):
    """ä¸ç°æœ‰ proto å®šä¹‰å¯¹æ¯”"""
    print(f"\n[å¯¹æ¯”] ä¸ç°æœ‰å®šä¹‰å¯¹æ¯”...")
    print(f"       ç°æœ‰ç›®å½•: {existing_dir}")
    
    if not os.path.exists(existing_dir):
        print(f"       âš ï¸ ç°æœ‰ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡å¯¹æ¯”")
        return
    
    new_files = set(f for f in os.listdir(output_dir) if f.endswith('.proto'))
    old_files = set(f for f in os.listdir(existing_dir) if f.endswith('.proto'))
    
    added = new_files - old_files
    removed = old_files - new_files
    common = new_files & old_files
    
    if added:
        print(f"       æ–°å¢æ–‡ä»¶: {', '.join(added)}")
    if removed:
        print(f"       ç§»é™¤æ–‡ä»¶: {', '.join(removed)}")
    
    # å¯¹æ¯”å…±åŒæ–‡ä»¶
    changed = []
    for f in common:
        new_path = os.path.join(output_dir, f)
        old_path = os.path.join(existing_dir, f)
        
        with open(new_path) as nf, open(old_path) as of:
            new_content = nf.read()
            old_content = of.read()
            
            # å¿½ç•¥æ³¨é‡Šè¡Œçš„å·®å¼‚
            new_lines = [l for l in new_content.split('\n') if not l.strip().startswith('//')]
            old_lines = [l for l in old_content.split('\n') if not l.strip().startswith('//')]
            
            if new_lines != old_lines:
                changed.append(f)
    
    if changed:
        print(f"       å†…å®¹å˜æ›´: {', '.join(changed)}")
    else:
        print(f"       æ— å†…å®¹å˜æ›´")


# ============================================================================
# å‘½ä»¤è¡Œå…¥å£
# ============================================================================

def main():
    parser = argparse.ArgumentParser(
        description='ä» Warp äºŒè¿›åˆ¶æå– Proto å®šä¹‰',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  %(prog)s                          # ä½¿ç”¨é»˜è®¤è·¯å¾„
  %(prog)s /path/to/binary          # æŒ‡å®šäºŒè¿›åˆ¶
  %(prog)s --output ./new_protos    # æŒ‡å®šè¾“å‡ºç›®å½•
  %(prog)s --compare ../proto       # ä¸ç°æœ‰å®šä¹‰å¯¹æ¯”
        """
    )
    
    parser.add_argument(
        'binary',
        nargs='?',
        default='/Applications/Warp.app/Contents/MacOS/stable',
        help='Warp äºŒè¿›åˆ¶è·¯å¾„ (é»˜è®¤: /Applications/Warp.app/Contents/MacOS/stable)'
    )
    
    parser.add_argument(
        '--output', '-o',
        default=None,
        help='è¾“å‡ºç›®å½• (é»˜è®¤: ./extracted_protos_YYYYMMDD_HHMMSS)'
    )
    
    parser.add_argument(
        '--compare', '-c',
        default=None,
        help='ä¸ç°æœ‰ proto ç›®å½•å¯¹æ¯”'
    )
    
    args = parser.parse_args()
    
    # æ£€æŸ¥äºŒè¿›åˆ¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.binary):
        print(f"âŒ äºŒè¿›åˆ¶æ–‡ä»¶ä¸å­˜åœ¨: {args.binary}")
        sys.exit(1)
    
    # è®¾ç½®è¾“å‡ºç›®å½•
    if args.output:
        output_dir = args.output
    else:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_dir = os.path.join(os.path.dirname(__file__), f'extracted_protos_{timestamp}')
    
    # æ‰§è¡Œæå–
    report = extract_protos(args.binary, output_dir)
    
    # å¯¹æ¯”
    if args.compare:
        compare_with_existing(output_dir, args.compare)
    
    # æç¤ºä¸é¡¹ç›® proto å¯¹æ¯”
    project_proto = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'proto')
    if os.path.exists(project_proto) and not args.compare:
        print(f"\nğŸ’¡ æç¤º: è¿è¡Œä»¥ä¸‹å‘½ä»¤ä¸é¡¹ç›® proto å¯¹æ¯”:")
        print(f"   python3 {__file__} --compare {project_proto}")


if __name__ == "__main__":
    main()
